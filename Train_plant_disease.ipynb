{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75784fb8-35bb-4b45-87d6-9c2bdb3bdfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddddd28c-8b25-4c95-b045-f3bb9a84bbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70295 files belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "## Data preprocessing\n",
    "###Training Image preprocessing\n",
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c94ef4-d86b-4a3d-a33d-ff245fdb1f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17572 files belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "##Validation Image Preprocessing\n",
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdaff8be-555a-4d03-89ba-0ae2908bd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Building Model\n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3a4938c-4330-494e-bfd3-7762aaa08b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c1f1e2-2e4a-4e32-8b6e-b54af0b22ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec41639-40cf-46ac-8f8f-6b0d2781de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e475cb9c-4c73-441a-a735-29308717ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ad3518-99d7-46ec-ba65-ecc3ec7e1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ee99867-6c8f-434f-82cb-ba766c51091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51b23f0b-9da2-4d02-917f-3f30e9df73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce54c9fd-45de-48e7-a9d8-74dc827fd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1500,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faa0c930-8d36-4afa-a35a-0653904489c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dropout(0.4)) #avoiding overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "982c24d9-01b0-4737-b11a-c4a233179abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output Layer\n",
    "cnn.add(tf.keras.layers.Dense(units=38,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c36c703-05c6-4bb8-ac2e-bed018d61162",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compiling and Training Phase\n",
    "cnn.compile(optimizer=tf.keras.optimizers.legacy.Adam(\n",
    "    learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cac8e8e6-2019-439d-9ad4-cb4aced1e6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 126, 126, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 63, 63, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 256)       147712    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1500)              3073500   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1500)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 38)                57038     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,547,722\n",
      "Trainable params: 7,547,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a453620-f3dc-4e7f-8059-c7fbf7842072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2197/2197 [==============================] - 4251s 2s/step - loss: 1.3773 - accuracy: 0.5934 - val_loss: 0.4979 - val_accuracy: 0.8458\n",
      "Epoch 2/10\n",
      "2197/2197 [==============================] - 3765s 2s/step - loss: 0.4464 - accuracy: 0.8589 - val_loss: 0.2972 - val_accuracy: 0.9067\n",
      "Epoch 3/10\n",
      "1012/2197 [============>.................] - ETA: 32:55 - loss: 0.2963 - accuracy: 0.9046"
     ]
    }
   ],
   "source": [
    "training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e7975-c31b-4618-a111-942c2e31efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22bf8f-10cd-4c49-a9aa-0d2b6928dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set Accuracy\n",
    "train_loss, train_acc = cnn.evaluate(training_set)\n",
    "print('Training accuracy:', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a347c82-340b-468a-8969-6487b171c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation set Accuracy\n",
    "val_loss, val_acc = cnn.evaluate(validation_set)\n",
    "print('Validation accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad5779-ae26-4479-90c0-4a6b5e39fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb70717-b7cc-4cf8-8b1d-1a8c55fd88a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('trained_plant_disease_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10119a20-d4cb-4de1-b52f-cf76243bf09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history.history #Return Dictionary of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a28962-3f70-49e4-88aa-1b6370698b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recording History in json\n",
    "import json\n",
    "with open('training_hist.json','w') as f:\n",
    "  json.dump(training_history.history,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df80f7-2b8c-4e7d-a6aa-a75a4b2da04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5206ac1-0fd7-4d79-b9e1-a09bfca78a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Accuracy Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbe8dd-175b-42a8-9c37-f917b8edf2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(1,11)]\n",
    "plt.plot(epochs,training_history.history['accuracy'],color='red',label='Training Accuracy')\n",
    "plt.plot(epochs,training_history.history['val_accuracy'],color='blue',label='Validation Accuracy')\n",
    "plt.xlabel('No. of Epochs')\n",
    "plt.title('Visualization of Accuracy Result')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a4cfb-97cb-4aa6-95e6-efa3a0966fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##other metrics for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa0be29-236d-44fa-8d7c-53b089c19257",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = validation_set.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792da9f-8a0a-436b-b386-533e92655180",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4375110-1de4-4880-9626-74259374290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn.predict(test_set)\n",
    "predicted_categories = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41a8af-b250-4e2c-b5eb-842c9e64fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_categories = tf.concat([y for x, y in test_set], axis=0)\n",
    "Y_true = tf.argmax(true_categories, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5632b7f8-af56-45cb-a674-1a73eb94b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018b8bb-3fdb-4615-947c-35f921f4d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd2912-093a-4883-91a2-10a3a2655166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(Y_true,predicted_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb49a90-5415-4968-9cd0-25d3626dd3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Recall Fscore\n",
    "print(classification_report(Y_true,predicted_categories,target_names=class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d1f19-433d-4f8c-b9e6-c6699fb79790",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Confusion Matrix Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e493a-d446-4770-9612-4e8d5be3cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(cm,annot=True,annot_kws={\"size\": 10})\n",
    "\n",
    "plt.xlabel('Predicted Class',fontsize = 20)\n",
    "plt.ylabel('Actual Class',fontsize = 20)\n",
    "plt.title('Plant Disease Prediction Confusion Matrix',fontsize = 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1980dfe-c53e-4831-97b3-ec566a60ab74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1400d788-ec7c-4e68-9181-887daccc297e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
